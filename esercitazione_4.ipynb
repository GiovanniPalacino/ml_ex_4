{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "487d6a0e",
      "cell_type": "markdown",
      "source": [
        "# **Esercitazione 4 - Classificatori: KNN e Decision Trees**\n",
        "\n",
        "In questa esercitazione applicheremo quanto appreso sui classificatori. Nello specifico utilizzeremo:\n",
        "\n",
        "* **K-Nearest Neighbors (KNN):** Un algoritmo di classificazione basato sulla similarità che assegna una classe a un'osservazione in base alle classi dei suoi \"K\" vicini più prossimi.\n",
        "\n",
        "* **Decision Trees:** Un modello di classificazione che utilizza una struttura ad albero per prendere decisioni basate su regole derivate dalle caratteristiche dei dati."
      ],
      "metadata": {
        "id": "487d6a0e"
      }
    },
    {
      "id": "1c0e7c81",
      "cell_type": "markdown",
      "source": [
        "### **Dataset Breast Cancer**\n",
        "\n",
        "Il dataset di riferimento sarà `breast_cancer`, un noto dataset di classificazione che contiene informazioni su tumori al seno. Le osservazioni includono diverse caratteristiche misurate sui tumori, come dimensioni, forma e altre metriche, con l'obiettivo di classificare i tumori in due categorie: **benigni** e **maligni**.\n",
        "\n",
        "Per questa esercitazione, utilizzeremo l'intero dataset, mantenendo le classi originali. Il dataset è composto da 569 campioni e 30 caratteristiche, e utilizzeremo questo set per costruire i modelli di classificazione.\n",
        "\n",
        "Il codice seguente esegue l'importazione delle librerie necessarie, il caricamento del dataset `breast_cancer` e la preparazione dei dati. In particolare, gestiremo i dati e le etichette in modo da facilitare l'uso dei classificatori K-Nearest Neighbors (KNN) e Decision Trees.\n",
        "\n",
        "Dal caricamente del dataset estrarremo anche i nomi delle feature e della variabile target perchè ci servirà più avanti."
      ],
      "metadata": {
        "id": "1c0e7c81"
      }
    },
    {
      "id": "08d3ff15",
      "cell_type": "code",
      "source": [
        "# Importazione delle librerie necessarie\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree"
      ],
      "metadata": {
        "id": "08d3ff15"
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "id": "8f8b8f61",
      "cell_type": "code",
      "source": [
        "# Caricamento del dataset Iris\n",
        "dataset = load_breast_cancer()\n",
        "X = dataset.data\n",
        "y = dataset.target\n",
        "\n",
        "# Estraggo nomi delle feature e dei target\n",
        "feature_names = dataset.feature_names\n",
        "target_names = dataset.target_names"
      ],
      "metadata": {
        "id": "8f8b8f61"
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "id": "724f22cb",
      "cell_type": "markdown",
      "source": [
        "### **Divisione e standardizzazione del dataset**\n",
        "\n",
        "Dividiamo il dataset in `train set`, `validation set` e `test set` utilizzando le proporzioni già impostate. Successivamente applichiamo la standardizzazione utilizzando `StandardScaler`."
      ],
      "metadata": {
        "id": "724f22cb"
      }
    },
    {
      "id": "84b8b157",
      "cell_type": "code",
      "source": [
        "# Usare le seguenti proporzioni per il train, validation e test\n",
        "train_fraction = 0.6\n",
        "validation_fraction = 0.2\n",
        "test_fraction = 0.2\n",
        "\n",
        "dati_completi = np.c_[X, y] #concateniamo dati e target per avere un'unica matrice\n",
        "\n",
        "n_total = dati_completi.shape[0]\n",
        "n_train = int(n_total * train_fraction)\n",
        "n_val = int(n_total * validation_fraction)\n",
        "n_test = n_total - n_train - n_val\n",
        "\n",
        "train_set = dati_completi[:n_train]\n",
        "validation_set = dati_completi[n_train:n_train + n_val]\n",
        "test_set = dati_completi[n_train + n_val:]\n",
        "\n",
        "X_train, y_train = train_set[:, :-1], train_set[:, -1]\n",
        "X_val, y_val = validation_set[:, :-1], validation_set[:, -1]\n",
        "X_test, y_test = test_set[:, :-1], test_set[:, -1]\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_val.shape, y_val.shape)\n",
        "print(X_test.shape, y_test.shape)\n",
        "\n",
        "# Standardizzazione\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "84b8b157"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5102c517",
      "cell_type": "markdown",
      "source": [
        "## **Esercizio 1: Implementare K-NN**\n",
        "\n",
        "Per implementare il classificatore K-Nearest Neighbors utilizzeremo la classe `sklearn.neighbors.KNeighborsClassifier` presente in `scikit-learn`. La documentazione è disponibile [a questo link](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html).\n",
        "\n",
        "Di seguito vediamo i parametri chiave che bisogna specificare al momento della creazione dell'istanza:\n",
        "\n",
        "* **`n_neighbors`**: Numero di vicini da considerare. Valori più elevati implicano una maggiore generalizzazione.\n",
        "* **`weights`**: Specifica come pesare i vicini; può essere `uniform` (tutti i vicini hanno lo stesso peso) o `distance` (i vicini più prossimi hanno un peso maggiore).\n",
        "* **`metric`**: Tipo di distanza da utilizzare per calcolare la distanza tra i punti (ad esempio, `euclidean`, `manhattan`, ecc.).\n",
        "\n",
        "### Esempio di sintassi per istanziare, addestrare e predire\n",
        "\n",
        "```python\n",
        "# Importo KNeighborsClassifier da scikit-learn\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# 1. Instanzio il modello KNN\n",
        "# Durante la creazione dell'istanza imposto i parametri che desidero\n",
        "model = KNeighborsClassifier(n_neighbors=5, weights='uniform', metric='euclidean')\n",
        "\n",
        "# 2. Train del modello utilizzando il metodo .fit()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 3. Calcolo delle predizioni utilizzando il metodo .predict()\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "5102c517"
      }
    },
    {
      "id": "90f5938f",
      "cell_type": "markdown",
      "source": [
        "### **Guida per la risoluzione del K-Nearest Neighbors (KNN)**\n",
        "\n",
        "Di seguito sono spiegati i passaggi principali per la risoluzione dell'esercizio utilizzando il classificatore K-Nearest Neighbors.\n",
        "\n",
        "1. **Creazione del modello:** Creare un'istanza della classe `KNeighborsClassifier`, specificando i parametri presentati poco sopra. In particolare vogliamo i seguenti parametri:\n",
        "\n",
        "    - `n_neighbors` = 5\n",
        "\n",
        "    - `weights` = `'uniform'` (o `'distance'` se vuoi dare un peso maggiore ai vicini più prossimi)\n",
        "\n",
        "    - `metric` = `'euclidean'` (puoi cambiare con `'manhattan'` se preferisci un'altra metrica di distanza)\n",
        "\n",
        "2. **Addestramento del modello:** Addestriamo il modello utilizzando il metodo `.fit()`. Il modello deve essere addestrato sui dati di training. Assicurati che i dati siano adeguatamente preprocessati e, se necessario, normalizzati o standardizzati.\n",
        "\n",
        "3. **Calcolo delle predizioni:** Calcoliamo le predizioni sul validation e sul test set utilizzando il metodo `.predict()` del modello.\n",
        "\n",
        "4. **Valutazione delle prestazioni del modello:** Calcoliamo l'accuracy del modello. Possono essere utilizzate anche altre metriche, come la precisione, il richiamo e il punteggio F1, per ottenere una valutazione più completa. Dobbiamo valutare il modello sia sul validation set che sul test set e infine stampare il valore di accuracy su entrambi i set.\n",
        "\n",
        "5. **Calcolare la matrice di confusione:** Calcolare la matrice di confusione."
      ],
      "metadata": {
        "id": "90f5938f"
      }
    },
    {
      "id": "6803b23b",
      "cell_type": "code",
      "source": [
        "# Step 1: Creazione del modello KNN\n",
        "\n",
        "model = KNeighborsClassifier(n_neighbors=5, weights='distance', metric='euclidean')"
      ],
      "metadata": {
        "id": "6803b23b"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "66ea01d4",
      "cell_type": "code",
      "source": [
        "# Step 2: Addestramento del modello KNN\n",
        "\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "66ea01d4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d396900e",
      "cell_type": "code",
      "source": [
        "# Step 3: Calcolo delle predizioni\n",
        "\n",
        "y_val_pred = model.predict(X_val)\n",
        "y_test_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "d396900e"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d40ef061",
      "cell_type": "code",
      "source": [
        "# Step 4: Valutazione del modello KNN\n",
        "\n",
        "correct_val = np.sum(y_val==y_val_pred)\n",
        "total_val = len(y_val)\n",
        "accuracy_val = correct_val/total_val if total_val>0 else 0\n",
        "\n",
        "correct_test = np.sum(y_test==y_test_pred)\n",
        "total_test = len(y_test)\n",
        "accuracy_test = correct_test/total_test if total_test>0 else 0\n",
        "\n",
        "print(f\"validation accuracy: {accuracy_val:4f}\")\n",
        "print(f\"test accuracy: {accuracy_test:4f}\")"
      ],
      "metadata": {
        "id": "d40ef061"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3142e27e",
      "cell_type": "markdown",
      "source": [
        "#### Funzione alternativa per il calcolo dell' accuracy\n",
        "\n",
        "Finora abbiamo calcolato manualmente il valore dell' accuracy. Ovvero abbiamo confrontato il vettore delle predizioni con il vettore dei target e successivamente contato quanti campioni combaciano, in modo da avere il numero di predizioni effettuate correttamente. Possiamo effettuare questo calcolo anche utilizzando una funzione di `sklearn`.\n",
        "\n",
        "La funzione `accuracy_score` infatti ci calcola in automatico il valore dell' accuracy. La sintassi per utilizarla è la seguente\n",
        "\n",
        "```python\n",
        "# Importo accuracy_score da scikit-learn\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "3142e27e"
      }
    },
    {
      "id": "354dc544",
      "cell_type": "code",
      "source": [
        "# Step 4.1: Calcolare l' accuracy con accuracy_score\n",
        "\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Accuracy sul validation set: {val_accuracy:.4f}\")\n",
        "print(f\"Accuracy sul test set: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "354dc544"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "9cc51143",
      "cell_type": "code",
      "source": [
        "# Step 5: Calcolare la matrice di confusione\n",
        "\n",
        "print(\"\\nConfusion Matrix (Validation):\")\n",
        "print(confusion_matrix(y_val, y_val_pred))\n",
        "\n",
        "print(\"\\nConfusion Matrix (Test):\")\n",
        "print(confusion_matrix(y_test, y_test_pred))"
      ],
      "metadata": {
        "id": "9cc51143"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c83cdbd2",
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_decision_boundary(knn_model, X_train, y_train):\n",
        "\n",
        "    h = 0.1\n",
        "    x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
        "    y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "\n",
        "    Z = knn_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    unique_classes = np.unique(y_train)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.contourf(xx, yy, Z, alpha=0.5, cmap=plt.cm.RdYlBu)\n",
        "\n",
        "    scatter = plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, edgecolors='k', marker='o',\n",
        "                          label='Training set', cmap=plt.cm.RdYlBu, s=20)\n",
        "\n",
        "    plt.title(f'Confini Decisionali di K-Nearest Neighbors')\n",
        "    plt.legend(scatter.legend_elements()[0], unique_classes, title='Classi')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "c83cdbd2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c4ef4dfc",
      "cell_type": "markdown",
      "source": [
        "### Visualizzazione K-NN\n",
        "\n",
        "Per visualizzare il margine di classificazione del nostro K-NN dobbiamo utilizzare soltanto 2 features. Poichè nel dataset ne sono presenti 30 abbiamo due soluzioni:\n",
        "\n",
        "1. **Utilizzare le prime due features del dataset:** soluzione più rapida ma che non ci garantisce un risultato ottimale, in quanto l' ordine delle features non ha alcuna rilevanza circa la loro importanza. **ATTENZIONE:** poichè stiamo utilizzando solo 2 features, dobbiamo riaddestrare il K-NN sul dataset ridotto.\n",
        "\n",
        "2. **Applicare PCA con 2 componenti:** applichiamo la PCA con due componenti che utilizziamo successivamente per trasformare i nostri dati.\n",
        "\n",
        "Di seguito applicheremo entrambe le soluzioni e alla fine confronteremo i risultati."
      ],
      "metadata": {
        "id": "c4ef4dfc"
      }
    },
    {
      "id": "8829d633",
      "cell_type": "code",
      "source": [
        "# Visualizzazione con due feature\n",
        "\n",
        "# Riduciamo il dataset prendendo soltanto le prime 2 features (colonne)\n",
        "X_2features = X[:, :2]\n",
        "\n",
        "n_total = dati_2f.shape[0]\n",
        "n_train = int(n_total * train_fraction)\n",
        "n_val = int(n_total * validation_fraction)\n",
        "n_test = n_total - n_train - n_val\n",
        "\n",
        "train_set_2f = dati_2f[:n_train]\n",
        "validation_set_2f = dati_2f[n_train:n_train + n_val]\n",
        "test_set_2f = dati_2f[n_train + n_val:]\n",
        "\n",
        "X_train_2f, y_train_2f = train_set_2f[:, :-1], train_set_2f[:, -1]\n",
        "X_val_2f, y_val_2f = validation_set_2f[:, :-1], validation_set_2f[:, -1]\n",
        "X_test_2f, y_test_2f = test_set_2f[:, :-1], test_set_2f[:, -1]\n",
        "\n",
        "# Standardizziamo il dataset ridotto\n",
        "\n",
        "scaler_2f = StandardScaler()\n",
        "X_train_2f_scaled = scaler_2f.fit_transform(X_train_2f)\n",
        "X_val_2f_scaled = scaler_2f.transform(X_val_2f)\n",
        "X_test_2f_scaled = scaler_2f.transform(X_test_2f)\n",
        "\n",
        "\n",
        "# Creiamo e addestriamo il K-NN sul dataset ridotto e scalato\n",
        "\n",
        "knn_2f = KNeighborsClassifier(n_neighbors=5, weights='distance', metric='euclidean')\n",
        "knn_2f.fit(X_train_2f_scaled, y_train_2f)\n",
        "\n",
        "\n",
        "# Utilizziamo la funzione plot_decision_boundary per visualizzare il confine decisionale\n",
        "\n",
        "plot_decision_boundary(knn_2f, X_train_2f_scaled, y_train_2f)"
      ],
      "metadata": {
        "id": "8829d633"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a641f56a",
      "cell_type": "code",
      "source": [
        "# Visualizzazione con PCA\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Applichiamo PCA per ridurre il dataset a 2 dimensioni. ATTENZIONE: per applicare PCA dobbiamo prima standardizzare.\n",
        "\n",
        "dati_completi = np.c_[X, y]\n",
        "\n",
        "# Suddivisione in train, validation e test set\n",
        "n_total = dati_completi.shape[0]\n",
        "n_train = int(n_total * train_fraction)\n",
        "n_val = int(n_total * validation_fraction)\n",
        "n_test = n_total - n_train - n_val\n",
        "\n",
        "train_set = dati_completi[:n_train]\n",
        "validation_set = dati_completi[n_train:n_train + n_val]\n",
        "test_set = dati_completi[n_train + n_val:]\n",
        "\n",
        "X_train, y_train = train_set[:, :-1], train_set[:, -1]\n",
        "X_val, y_val = validation_set[:, :-1], validation_set[:, -1]\n",
        "X_test, y_test = test_set[:, :-1], test_set[:, -1]\n",
        "\n",
        "# Standardizzazione\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# Riduzione delle dimensioni con PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "\n",
        "\n",
        "# Classificatore KNN su dati PCA\n",
        "\n",
        "knn_pca = KNeighborsClassifier(n_neighbors=5, weights='uniform', metric='euclidean')\n",
        "knn_pca.fit(X_train_pca, y_train)\n",
        "\n",
        "\n",
        "# Plot\n",
        "\n",
        "plot_decision_boundary(knn_pca, X_train_pca, y_train)"
      ],
      "metadata": {
        "id": "a641f56a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f4c49b73",
      "cell_type": "markdown",
      "source": [
        "## **Esercizio 2: valutare le prestazioni di K-NN al variare di k e metrica**\n",
        "\n",
        "Valutiamo come variano le prestazioni del classificatore al variare di:\n",
        "\n",
        "* **k:** usiamo diversi valori di k.\n",
        "\n",
        "* **metrica**: usiamo diverse distanze, non solo quella euclidea.\n",
        "\n",
        "\n",
        "### **Guida:**\n",
        "\n",
        "1. **Testiamo il classificatore al variare del parametro:** che sia il k o la distanza, dobbiamo istanziare, allenare e valutare il classificatore per ogni valore che ci interessa. Alla fine di ogni test che effettuiamo, saliamo il valore di accuracy ottenuto in una lista.\n",
        "\n",
        "2. **Valutazione grafica:** utilizziamo la funzione di plot per valutare quale valore del parametro di interesse ci fa ottenere la performance migliore.\n",
        "\n"
      ],
      "metadata": {
        "id": "f4c49b73"
      }
    },
    {
      "id": "c5068b74",
      "cell_type": "code",
      "source": [
        "# Funzione per la valutazione grafica\n",
        "\n",
        "def plot_accuracy_k(k_values, train_scores, test_scores):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    plt.plot(k_values, train_scores, 'o-', label='Accuratezza Training')\n",
        "    plt.plot(k_values, test_scores, 'o-', label='Accuratezza Testing')\n",
        "\n",
        "    plt.xlabel('Numero di k')\n",
        "    plt.ylabel('Accuratezza')\n",
        "    plt.title('KNN: Accuratezza vs. Valore di k')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "c5068b74"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "57f7baf2",
      "cell_type": "code",
      "source": [
        "# Valutiamo le performance al variare di k\n",
        "\n",
        "k_values = range(1, 15)\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "\n",
        "# Istanziamo, alleniamo e valutiamo un K-NN per ogni valore di k\n",
        "\n",
        "for k in k_values:\n",
        "\n",
        "    knn = KNeighborsClassifier(n_neighbors=k, weights='uniform', metric='euclidean')\n",
        "\n",
        "\n",
        "    knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "\n",
        "    train_pred = knn.predict(X_train_scaled)\n",
        "    test_pred = knn.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "    train_accuracy = accuracy_score(y_train, train_pred)\n",
        "    test_accuracy = accuracy_score(y_test, test_pred)\n",
        "\n",
        "    # Salviamo i risultati\n",
        "    train_scores.append(train_accuracy)\n",
        "    test_scores.append(test_accuracy)\n",
        "\n",
        "\n",
        "# Visualizziamo le performance al variare di k\n",
        "# N.B. la funzione plot_accuracy_k ha bisogno dei parametri k_values, train_scores, test_scores.\n",
        "plot_accuracy_k(k_values, train_scores, test_scores)"
      ],
      "metadata": {
        "id": "57f7baf2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2a66262d",
      "cell_type": "code",
      "source": [
        "# Funzione per plottare l' accuracy al variare delle metriche\n",
        "\n",
        "def plot_accuracy_metric(metrics, train_scores, test_scores):\n",
        "    bar_width = 0.35\n",
        "    x = np.arange(len(metrics))\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    color_train = plt.cm.RdYlBu(0.9)\n",
        "    color_test = plt.cm.RdYlBu(0.4)\n",
        "\n",
        "    bars_train = plt.bar(x - bar_width/2, train_scores.values(), width=bar_width, label='Training', color=color_train)\n",
        "    bars_test = plt.bar(x + bar_width/2, test_scores.values(), width=bar_width, label='Testing', color=color_test)\n",
        "\n",
        "    plt.xticks(ticks=x, labels=metrics)\n",
        "    plt.xlabel('Metriche')\n",
        "    plt.ylabel('Accuratezza')\n",
        "    plt.title('KNN: Accuratezza vs. Metriche')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.grid(axis='y')\n",
        "\n",
        "    for bar in bars_train:\n",
        "        yval = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
        "\n",
        "    for bar in bars_test:\n",
        "        yval = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "2a66262d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "7021496a",
      "cell_type": "code",
      "source": [
        "# Valutiamo le performance al variare della metrica\n",
        "# in questo caso le performance devono essere salvate in un dizionario. Ogni chiave sarà il nome della metrica usata, il valore corrispondente invece sarà l' accuracy ottenuta.\n",
        "\n",
        "metrics = ['euclidean', 'manhattan', 'minkowski', 'cosine']\n",
        "test_scores = {}\n",
        "train_scores = {}\n",
        "\n",
        "# Istanziamo, alleniamo e valutiamo un K-NN per ogni metrica. Utilizziamo k=5.\n",
        "\n",
        "for metric in metrics:\n",
        "    # Creiamo un'istanza del modello K-NN con k=5\n",
        "    knn = KNeighborsClassifier(n_neighbors=5, weights='uniform', metric=metric)\n",
        "\n",
        "    # Addestriamo il modello sui dati di training\n",
        "    knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Prediciamo sui dati di training e di test\n",
        "    train_pred = knn.predict(X_train_scaled)\n",
        "    test_pred = knn.predict(X_test_scaled)\n",
        "\n",
        "    # Calcoliamo l'accuratezza per training e test set\n",
        "    train_accuracy = accuracy_score(y_train, train_pred)\n",
        "    test_accuracy = accuracy_score(y_test, test_pred)\n",
        "\n",
        "    # Salviamo i risultati nei dizionari\n",
        "    train_scores[metric] = train_accuracy\n",
        "    test_scores[metric] = test_accuracy\n",
        "\n",
        "\n",
        "# Visualizziamo le performance al variare della metrica\n",
        "# N.B. la funzione plot_accuracy_metric ha bisogno dei parametri metrics, train_scores, test_scores.\n",
        "\n",
        "plot_accuracy_metric(metrics, train_scores, test_scores)"
      ],
      "metadata": {
        "id": "7021496a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "432f7f94",
      "cell_type": "markdown",
      "source": [
        "## **Esercizio 2: Implementare Decision Trees**\n",
        "\n",
        "Per implementare il classificatore Decision Tree, utilizzeremo la classe `sklearn.tree.DecisionTreeClassifier` presente in `scikit-learn`. La documentazione è disponibile [a questo link](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html).\n",
        "\n",
        "Di seguito vediamo i parametri chiave che bisogna specificare al momento della creazione dell'istanza:\n",
        "\n",
        "* **`criterion`**: Funzione da utilizzare per misurare la qualità di uno split.\n",
        "\n",
        "* **`max_depth`**: Profondità massima dell'albero. Limitare la profondità aiuta a prevenire l'overfitting.\n",
        "\n",
        "* **`min_samples_split`**: Numero minimo di campioni richiesti per dividere un nodo. Valori più alti rendono l'albero più conservativo.\n",
        "\n",
        "* **`min_samples_leaf`**: Numero minimo di campioni che devono essere presenti in un nodo foglia. Prevenire nodi foglia con pochi campioni può migliorare la generalizzazione.\n",
        "\n",
        "\n",
        "### Esempio di sintassi per istanziare, addestrare e predire\n",
        "\n",
        "```python\n",
        "# Importo DecisionTreeClassifier da scikit-learn\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 1. Instanzio il modello Decision Tree\n",
        "# Durante la creazione dell'istanza imposto i parametri che desidero\n",
        "model = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=10)\n",
        "\n",
        "# 2. Train del modello utilizzando il metodo .fit()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 3. Calcolo delle predizioni utilizzando il metodo .predict()\n",
        "predictions = model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "432f7f94"
      }
    },
    {
      "id": "afcba9f7",
      "cell_type": "markdown",
      "source": [
        "## **Esercizio 3: Istanziare allenare e valutare un modello DecisionTree**\n",
        "\n",
        "In linea con quanto visto finora, istanziamo, alleniamo e valutiamo un modello di DecisionTree. Utilizziamo:\n",
        "\n",
        "* `criterion`=`'entropy'`\n",
        "\n",
        "* `random_state` = 42\n",
        "\n",
        "Il valore di `random_state` non ha un significato particolare, ma ci permette di rendere l' esperimento deterministico.\n",
        "\n",
        "I passaggi per questo esercizio sono uguali a quanto visto in precedenza per K-NN."
      ],
      "metadata": {
        "id": "afcba9f7"
      }
    },
    {
      "id": "29449cdc",
      "cell_type": "code",
      "source": [
        "# Importiamo DecisionTree\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree"
      ],
      "metadata": {
        "id": "29449cdc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "54090eec",
      "cell_type": "code",
      "source": [
        "# Step 1 - Creiamo un albero decisionale\n",
        "\n",
        "DecisionTree = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=10)\n",
        "\n",
        "\n",
        "# Step 2 - Alleniamo il modello\n",
        "\n",
        "DecisionTree.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Step 3 - Calcoliamo le predizioni sui dati di test\n",
        "\n",
        "predictions = DecisionTree.predict(X_test)\n",
        "\n",
        "\n",
        "# Step 4 - Valutiamo il modello, calcoliamo accuracy e confusion matrix\n",
        "\n",
        "# Calcoliamo l'accuracy\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "\n",
        "# Calcoliamo la matrice di confusione\n",
        "conf_matrix = confusion_matrix(y_test, predictions)\n",
        "\n",
        "# Visualizziamo i risultati\n",
        "print(f'Accuratezza del modello: {accuracy:.4f}')\n",
        "print(\"\\nMatrice di Confusione:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "id": "54090eec"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e7a16dfe",
      "cell_type": "code",
      "source": [
        "# Visualizzazione dell'albero creato\n",
        "# dovete sostituire alla funzione plot_tree il primo parametro. Nello specifico dovete sostituirlo con il nome che avete dato al vostro DecisionTree.\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "plot_tree(dt_classifier, feature_names=feature_names, class_names=target_names,\n",
        "          filled=True, rounded=True, fontsize=12)\n",
        "plt.title('Decision Tree')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "e7a16dfe",
        "outputId": "7104924c-2ab0-46af-e8ac-57f006cd6af4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'dt_classifier' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-e9dd8b83ac6e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m plot_tree(dt_classifier, feature_names=feature_names, class_names=target_names, \n\u001b[0m\u001b[1;32m      6\u001b[0m           filled=True, rounded=True, fontsize=12)\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Decision Tree'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dt_classifier' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1000 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "id": "4ff6d7f0",
      "cell_type": "markdown",
      "source": [
        "## **Esercizio 4: Valutiamo le performance di un DecisionTree al variare di alcuni parametri**\n",
        "\n",
        "Come abbiamo fatto per K-NN, vogliamo valutare come variano le performance di un Decision Tree al variare di alcuni parametri. Nello specifico vogliamo valutare il modello al variare di:\n",
        "\n",
        "* **`max_depth`**: Profondità massima dell'albero.\n"
      ],
      "metadata": {
        "id": "4ff6d7f0"
      }
    },
    {
      "id": "689aea93",
      "cell_type": "code",
      "source": [
        "# Funzione per plottare l' accuracy al variare della max_depth del modello\n",
        "\n",
        "def plot_accuracy_depth(k_values, train_scores, test_scores):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    plt.plot(k_values, train_scores, 'o-', label='Accuratezza Training')\n",
        "    plt.plot(k_values, test_scores, 'o-', label='Accuratezza Testing')\n",
        "\n",
        "    plt.xlabel('Profondità massima dell\\'albero')\n",
        "    plt.ylabel('Accuratezza')\n",
        "    plt.title('Decision Tree: Accuratezza vs. Depth')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "689aea93"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "7f9d03e7",
      "cell_type": "code",
      "source": [
        "# Confrontiamo alberi con diverse profondità massime\n",
        "\n",
        "max_depths = [2, 3, 4, 5]\n",
        "train_accuracy = []\n",
        "test_accuracy = []\n",
        "\n",
        "# Istanziamo, alleniamo e valutiamo un DecisionTree per ogni valore di max_depth\n",
        "\n",
        "for max_depth in max_depths:\n",
        "\n",
        "    DecisionTree = DecisionTreeClassifier(criterion='entropy', max_depth=max_depth, random_state=42)\n",
        "\n",
        "    # Addestriamo il modello\n",
        "    DecisionTree.fit(X_train, y_train)\n",
        "\n",
        "    # Calcoliamo le predizioni\n",
        "    train_pred = DecisionTree.predict(X_train)\n",
        "    test_pred = DecisionTree.predict(X_test)\n",
        "\n",
        "    # Calcoliamo l'accuratezza su training e test\n",
        "    train_accuracy.append(accuracy_score(y_train, train_pred))\n",
        "    test_accuracy.append(accuracy_score(y_test, test_pred))\n",
        "\n",
        "\n",
        "# Visualizziamo l'effetto della profondità sull'accuratezza\n",
        "\n",
        "plot_accuracy_depth(max_depths, train_accuracy, test_accuracy)"
      ],
      "metadata": {
        "id": "7f9d03e7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "58b02676",
      "cell_type": "markdown",
      "source": [
        "## **Esercizio 5: Ottimizzazione Decision Tree con GridSearch e Cross Validation**\n",
        "\n",
        "Possiamo ottimizzare le performance di un Decision Tree specificando ulteriori parametri. Lo scopo di questo esercizio è trovare la miglior combinazione di parametri che massimizza l' accuracy del nostro modello. Per trovare questa configurazione utilizzeremo la funzione `GridSearchCV` che effettua Grid Search e Cross Validation contemporaneamente.\n",
        "\n",
        "Innanzitutto proviamo a istanziare un Decision Tree specificando più parametri. Nello specifico impostiamo:\n",
        "\n",
        "* `max_depth` = `3`\n",
        "\n",
        "* `min_samples_split` = `5`\n",
        "\n",
        "* `min_samples_leaf` = `2`\n",
        "\n",
        "Vediamo se l' aggiunta di questi parametri incrementa le performance ottenute precedentemente.\n",
        "\n",
        "Ovviamente i parametri impostati precedentemente devono essere mantenuti."
      ],
      "metadata": {
        "id": "58b02676"
      }
    },
    {
      "id": "12b14dc2",
      "cell_type": "code",
      "source": [
        "# Albero ottimizzato con parametri più controllati\n",
        "\n",
        "# Istanziamo il nuovo albero specificando tutti i parametri di cui abbiamo bisogno.\n",
        "\n",
        "secondo_albero = DecisionTreeClassifier(\n",
        "    criterion='entropy',\n",
        "    max_depth=5,\n",
        "    min_samples_split=10,\n",
        "    min_samples_leaf=5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# Alleniamo l' albero\n",
        "\n",
        "secondo_albero.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Effettuare le predizioni del nuovo albero allenato\n",
        "\n",
        "test_pred = secondo_albero.predict(X_test)\n",
        "\n",
        "\n",
        "# Rappresentiamo il nuovo albero\n",
        "# Dovete sostituire il primo parametro della funzione plot_tree con il nome del vostro albero.\n",
        "\n",
        "plt.figure(figsize=(15, 8))\n",
        "plot_tree(secondo_albero, feature_names=feature_names, class_names=target_names,\n",
        "          filled=True, rounded=True, fontsize=10)\n",
        "plt.title('Albero Decisionale')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "12b14dc2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "65dda958",
      "cell_type": "markdown",
      "source": [
        "#### **Importanza delle features**\n",
        "\n",
        "Possiamo estrarre dal nostro modello Decision Tree l' importanza delle singole feature, cioè quanto una feature aiuda a ridurre il criterio scelto, l' entropia nel nostro caso.\n",
        "\n",
        "Questa informazione è contenuta in `.feature_importances_`.\n",
        "\n",
        "Una volta estratti questi valori, ordiniamoli in ordine decrescente e utilizziamo la funzione `plot_top_feature_importance` definita nella cella seguente per rappresentarne il grafico. La funzione richiede due parametri:\n",
        "\n",
        "* **Vettore importanze:** il vettore contenente l' importanza delle features ottenuto dall' estrazione.\n",
        "\n",
        "* **Nomi delle features:** i nomi delle feature che abbiamo estratto all' inizio dell' esercitazione quando abbiamo importato il dataset."
      ],
      "metadata": {
        "id": "65dda958"
      }
    },
    {
      "id": "e43f274b",
      "cell_type": "code",
      "source": [
        "def plot_top_feature_importance(importances, feature_names):\n",
        "    # Ordina le importanze e ottieni i primi `top_n` indici\n",
        "    top_n=10\n",
        "    indices = np.argsort(importances)[::-1][:top_n]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.title('Importanza delle Feature')\n",
        "\n",
        "    # Plotta solo le prime `top_n` barre\n",
        "    plt.bar(range(top_n), importances[indices], align='center', color='skyblue')\n",
        "\n",
        "    plt.xticks(range(top_n), [feature_names[i] for i in indices], rotation=45)\n",
        "    plt.xlabel('Feature')\n",
        "    plt.ylabel('Importanza')\n",
        "    plt.tight_layout()  # Aggiunge spazio tra i lati del grafico\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "e43f274b"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "30b07808",
      "cell_type": "code",
      "source": [
        "# Estrai l' importanza delle features da .feature_importances_\n",
        "\n",
        "importances = secondo_albero.feature_importances_\n",
        "\n",
        "\n",
        "# Riordina in ordine decrescente\n",
        "\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "\n",
        "# Rappresentiamo il grafico\n",
        "\n",
        "plot_top_feature_importance(importances, feature_names)"
      ],
      "metadata": {
        "id": "30b07808"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "b437e3d1",
      "cell_type": "markdown",
      "source": [
        "### **Grid search**\n",
        "\n",
        "Poichè i parametri impostabili in un modello sono numerosi testare le singole configurazioni è dispendioso. Tuttavia la ricerca dei parametri ottimali è l' unico modo che abbiamo per assicurarci di estrarre la miglior performance dal nostro modello. In questi casi ci sono diverse strateggie per cercare la configurazione migliore. Una di questa è la **Grid search** (letteralmente **ricerca a griglia**) che consiste nel testare tutte le possibili configurazioni e selezionare la migliore. Chiaramente testare tutte le configurazioni rende il grid search un algoritmo molto dispendioso dal punto di vista computazionale.\n",
        "\n",
        "Possiamo implementare un algoritmo di grid search utilizzando la classe `GridSearchCV` di `sklearn` che effettua contemporaneamente ricerca a griglia e cross-validation.\n",
        "\n",
        "#### Guida per Grid Search:\n",
        "\n",
        "I seguenti passaggi devono guidarvi all' utilizzo di `GridSearchCV` per trovare la miglior configurazione per un modello di DecisionTree per il nostro dataset.\n",
        "\n",
        "1. **Istanziamo un' oggetto `GridSearchCV`:** per creare l' oggetto `GridSearchCV` dobbiamo specificare i seguenti parametri\n",
        "\n",
        "    * Modello che vogliamo usare\n",
        "\n",
        "    * Dizionario contenente come chiavi i parametri che vogliamo testare, e come value i valori che vogliamo impiegare\n",
        "\n",
        "    * `cv` cioè il nomero di fold che vogliamo utilizzare per la cross-validaton\n",
        "\n",
        "    * `scoring` ovvero la metrica da utilizzare per valutare, ad esempio `accuracy`\n",
        "\n",
        "2. **Eseguire Grid Search:** utilizziamo il metodo `.fit()` dell' oggetto `GridSearchCV` definito al punto 1 per eseguire l' algoritmo\n",
        "\n",
        "3. **Stampare configurazione migliore:** dopo aver eseguito il `.fit()`, l' oggetto `GridSearchCV` ci permette di accedere ad alcuni attributi:\n",
        "\n",
        "    * `.best_params_`: un dizionario che rappresenta la miglior configurazione.\n",
        "\n",
        "    * `.best_scores_`: il valore migliore ottenuto come accuracy.\n",
        "\n",
        "    * `.best_estimator_`: il modello allenato con la configurazione migliore."
      ],
      "metadata": {
        "id": "b437e3d1"
      }
    },
    {
      "id": "851f3973",
      "cell_type": "code",
      "source": [
        "# Step 1 - Istanziare l' oggetto GridSearchCV\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Definizione del grid di parametri\n",
        "param_grid = {\n",
        "    'max_depth': [3, 4, 5, 6, 7, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'criterion': ['entropy']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=dt_model, param_grid=param_grid, cv=5, scoring='accuracy')"
      ],
      "metadata": {
        "id": "851f3973"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "91b20d57",
      "cell_type": "code",
      "source": [
        "# Step 2 - Eseguire Grid Search\n",
        "\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "91b20d57"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "bd109bd5",
      "cell_type": "code",
      "source": [
        "# Step 3 - Stampare i risultati\n",
        "# Stampare la migliore configurazione e la migliore accuracy\n",
        "\n",
        "# Migliori parametri trovati\n",
        "print(\"Migliori parametri:\", grid_search.best_params_)\n",
        "\n",
        "# Migliore accuratezza ottenuta\n",
        "print(\"Migliore accuratezza:\", grid_search.best_score_)\n",
        "\n",
        "# Modello allenato con la miglior configurazione\n",
        "best_model = grid_search.best_estimator_\n",
        "print(\"Miglior modello:\", best_model)"
      ],
      "metadata": {
        "id": "bd109bd5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "18b8e613",
      "cell_type": "markdown",
      "source": [
        "# **Esercizio 6: Model Selection classificatori**\n",
        "\n",
        "Avendo affrontato tutti i classificatori visti in questo corso, possiamo adesso procedere alla fase di **model selection**. Vogliamo trovare quale classificatore la relativa configurazione che meglio performano su uno specifico dataset.\n",
        "\n",
        "### **Dataset**\n",
        "\n",
        "Per questo esercizio utilizzeremo il dataset `Vehicle Silhouette` che trovato al seguente [link](https://archive.ics.uci.edu/dataset/149/statlog+vehicle+silhouettes). Il dataset contiene 846 campioni su 18 features, e contiene informazioni circa le dimensioni di alcuni veicoli. L' obiettivo è classificare ogni campione in 4 possibili classi."
      ],
      "metadata": {
        "id": "18b8e613"
      }
    },
    {
      "id": "bab558cf",
      "cell_type": "code",
      "source": [
        "!pip install ucimlrepo"
      ],
      "metadata": {
        "id": "bab558cf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "8ffb9b39",
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "statlog_vehicle_silhouettes = fetch_ucirepo(id=149)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = statlog_vehicle_silhouettes.data.features\n",
        "y = statlog_vehicle_silhouettes.data.targets"
      ],
      "metadata": {
        "id": "8ffb9b39"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "10713cae",
      "cell_type": "code",
      "source": [
        "# svolgimento..."
      ],
      "metadata": {
        "id": "10713cae"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}